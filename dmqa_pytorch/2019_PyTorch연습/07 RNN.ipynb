{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습합니다: cuda\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "lr = 0.001\n",
    "EPOCHS = 10\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"다음 기기로 학습합니다:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
    "LABEL = data.Field(sequential=False, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a winters day, 28th december 1986, two bored 14 year olds hire a movie. \"hmmmm, police story, looks interesting\", \"who is this jackie chan?\", \"never heard of him\". two hours later after watching the film, in a daze, we wanted to know more. 16 years later (and severely out of pocket from collecting jc movies!) the film still grabs me like no other. ok, maybe i have a soft spot for it as it was my \"first\" (cannonball run doesn't count!!) jc movie, but it is an excellent movie. it has all the classic jc elements, action, humour, action, heart and action! some comments say it's dated, it was made in 1985, of course it's dated! but then so must jaws, casablanca, singin' in the rain and the godfather!!!!!! without movies like police story where would hollywood action be today? ps set standards, many a scene has been stolen for use in other movies. to really fully appreciate it you must see it in widescreen, you miss so much of the movie otherwise (yes, he really does fall off the bus going round the corner!). if you haven't already, see this movie now!!!!<br /><br />\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(vars(trainset.examples[0])['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'winters', 'day,', '28th', 'december', '1986,', 'two', 'bored', '14', 'year', 'olds', 'hire', 'a', 'movie.', '\"hmmmm,', 'police', 'story,', 'looks', 'interesting\",', '\"who', 'is', 'this', 'jackie', 'chan?\",', '\"never', 'heard', 'of', 'him\".', 'two', 'hours', 'later', 'after', 'watching', 'the', 'film,', 'in', 'a', 'daze,', 'we', 'wanted', 'to', 'know', 'more.', '16', 'years', 'later', '(and', 'severely', 'out', 'of', 'pocket', 'from', 'collecting', 'jc', 'movies!)', 'the', 'film', 'still', 'grabs', 'me', 'like', 'no', 'other.', 'ok,', 'maybe', 'i', 'have', 'a', 'soft', 'spot', 'for', 'it', 'as', 'it', 'was', 'my', '\"first\"', '(cannonball', 'run', \"doesn't\", 'count!!)', 'jc', 'movie,', 'but', 'it', 'is', 'an', 'excellent', 'movie.', 'it', 'has', 'all', 'the', 'classic', 'jc', 'elements,', 'action,', 'humour,', 'action,', 'heart', 'and', 'action!', 'some', 'comments', 'say', \"it's\", 'dated,', 'it', 'was', 'made', 'in', '1985,', 'of', 'course', \"it's\", 'dated!', 'but', 'then', 'so', 'must', 'jaws,', 'casablanca,', \"singin'\", 'in', 'the', 'rain', 'and', 'the', 'godfather!!!!!!', 'without', 'movies', 'like', 'police', 'story', 'where', 'would', 'hollywood', 'action', 'be', 'today?', 'ps', 'set', 'standards,', 'many', 'a', 'scene', 'has', 'been', 'stolen', 'for', 'use', 'in', 'other', 'movies.', 'to', 'really', 'fully', 'appreciate', 'it', 'you', 'must', 'see', 'it', 'in', 'widescreen,', 'you', 'miss', 'so', 'much', 'of', 'the', 'movie', 'otherwise', '(yes,', 'he', 'really', 'does', 'fall', 'off', 'the', 'bus', 'going', 'round', 'the', 'corner!).', 'if', 'you', \"haven't\", 'already,', 'see', 'this', 'movie', 'now!!!!<br', '/><br', '/>']\n"
     ]
    }
   ],
   "source": [
    "print(vars(trainset.examples[0])['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trainset, min_freq=5)\n",
    "LABEL.build_vocab(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset = trainset.split(split_ratio=0.8)\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
    "    (trainset, valset, testset),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(TEXT.vocab)\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[학습셋]: 20000 [검증셋]: 5000 [테스트셋]: 25000 [단어셋]: 46159 [클래스]: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"[학습셋]: {} [검증셋]: {} [테스트셋]: {} [단어셋]: {} [클래스]: {}\".format(len(trainset), len(valset), len(testset), vocab_size, n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicGRU(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
    "        super(BasicGRU, self).__init__()\n",
    "        print(\"Building Basic GRU model...\")\n",
    "        self.n_layers = n_layers\n",
    "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
    "                          num_layers=self.n_layers,\n",
    "                          batch_first=True)\n",
    "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        h_0 = self._init_state(batch_size=x.size(0))\n",
    "        x, _ = self.gru(x, h_0)  # [i, b, h]\n",
    "        h_t = x[:,-1,:]\n",
    "        self.dropout(h_t)\n",
    "        logit = self.out(h_t)  # [b, h] -> [b, o]\n",
    "        return logit\n",
    "    \n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_iter):\n",
    "    model.train()\n",
    "    for b, batch in enumerate(train_iter):\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        y.data.sub_(1)  # 레이블 값을 0과 1로 변환\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    \"\"\"evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    corrects, total_loss = 0, 0\n",
    "    for batch in val_iter:\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        y.data.sub_(1) # 레이블 값을 0과 1로 변환\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y, reduction='sum')\n",
    "        total_loss += loss.item()\n",
    "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "    size = len(val_iter.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100.0 * corrects / size\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Basic GRU model...\n"
     ]
    }
   ],
   "source": [
    "model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[이폭: 1] 검증 오차: 0.69 | 검증 정확도:51.00\n",
      "[이폭: 2] 검증 오차: 0.69 | 검증 정확도:50.00\n",
      "[이폭: 3] 검증 오차: 0.70 | 검증 정확도:51.00\n",
      "[이폭: 4] 검증 오차: 0.68 | 검증 정확도:53.00\n",
      "[이폭: 5] 검증 오차: 0.37 | 검증 정확도:84.00\n",
      "[이폭: 6] 검증 오차: 0.32 | 검증 정확도:86.00\n",
      "[이폭: 7] 검증 오차: 0.34 | 검증 정확도:87.00\n",
      "[이폭: 8] 검증 오차: 0.37 | 검증 정확도:86.00\n",
      "[이폭: 9] 검증 오차: 0.42 | 검증 정확도:86.00\n",
      "[이폭: 10] 검증 오차: 0.40 | 검증 정확도:87.00\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "for e in range(1, EPOCHS+1):\n",
    "    train(model, optimizer, train_iter)\n",
    "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
    "\n",
    "    print(\"[이폭: %d] 검증 오차:%5.2f | 검증 정확도:%5.2f\" % (e, val_loss, val_accuracy))\n",
    "    \n",
    "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        if not os.path.isdir(\"snapshot\"):\n",
    "            os.makedirs(\"snapshot\")\n",
    "        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 오차:  0.33 | 테스트 정확도: 85.00\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./snapshot/txtclassification.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iter)\n",
    "print('테스트 오차: %5.2f | 테스트 정확도: %5.2f' % (test_loss, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmqa_pytorch",
   "language": "python",
   "name": "dmqa_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
