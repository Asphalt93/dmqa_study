{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Series\n",
    "\n",
    "\n",
    "<span style=\"color:gray\">\n",
    "<br>\n",
    "\n",
    "1. Neural Net - part.1\n",
    "\n",
    "</span>\n",
    "\n",
    "2. <b>Convolution Neural Network</b>\n",
    "\n",
    "\n",
    "<span style=\"color:gray\">\n",
    "\n",
    "3. Neural Net - part.2\n",
    "\n",
    "\n",
    "4. Recursive Nerural Network\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 256\n",
    "learning_rate = 0.0002\n",
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(),\n",
    "                        target_transform=None, download = True)\n",
    "mnist_test = dset.MNIST(\"./\", train=False, transform=transforms.ToTensor(),\n",
    "                        target_transform=None, download = True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*3*3, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = self.fc_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Layer\n",
    "<img src=\"img/CNN_01.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* in_channels ::: \n",
    "    - ㅇㅇㅇ\n",
    "\n",
    "\n",
    "* out_channels ::: \n",
    "    - ㅇㅇㅇ\n",
    "\n",
    "\n",
    "* kernel_size ::: \n",
    "    - 커널 사이즈는 필터의 크기로 만일 2로 설정된다면 2x2 사이즈의 필터가 생성된다.\n",
    "\n",
    "\n",
    "* stride\n",
    "    - 출력크기를 조정할 목적으로 사용된다.\n",
    "    - 필터를 적용하는 위치의 간격으로, 스트라이드의 수만큼 필터가 이동하게 된다.\n",
    "\n",
    "\n",
    "* padding \n",
    "    - 출력 크기를 조정할 목적으로 사용된다.\n",
    "    - 입력 데이터 주변을 특정 값(예컨대 0)으로 채우는 방법이 있다.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layer\n",
    "<img src=\"img/CNN_02.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938d6ce5a07a4b27ac20fc0ad3e70335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "for i in tqdm_notebook(range(num_epoch)):\n",
    "    for j,[image, label] in enumerate(train_loader):\n",
    "        x = image.to(device)\n",
    "        y_= label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output, y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if j%1000 == 0:\n",
    "            print(loss)\n",
    "            loss_arr.append(loss.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 98.83814239501953\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image,label in test_loader:\n",
    "        x = image.to(device)\n",
    "        y_= label.to(device)\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        _, output_index = torch.max(output, 1)\n",
    "        \n",
    "        total += label.size(0)\n",
    "        correct += (output_index == y_).sum().float()\n",
    "    \n",
    "    print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmqa_pytorch",
   "language": "python",
   "name": "dmqa_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
